{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, num_vals, id, alpha=1.) -> None:\n",
    "        \"\"\"\n",
    "            num_vals: Int\n",
    "            id: Int\n",
    "            alpha: Float (dirichlet's alpha)\n",
    "        \"\"\"\n",
    "        self.id = id\n",
    "        self.num_vals = num_vals\n",
    "        self.local_marginal_probs = pd.DataFrame({f\"X{self.id}\": [i for i in range(num_vals)]})\n",
    "        self.parents = []\n",
    "        self.cur_val = -1\n",
    "        self.alpha = alpha\n",
    "        self.local_conditional_probs = None\n",
    "        \n",
    "    def set_parents(self, parents):\n",
    "        \"\"\"\n",
    "            parents: List[Node]\n",
    "        \"\"\"\n",
    "        # print(f\"Node {self.id} have parents: {[pa.id for pa in parents]}\")\n",
    "        self.parents = parents\n",
    "        return\n",
    "        \n",
    "    def get_level(self):\n",
    "        if len(self.parents):\n",
    "            return max([pa.get_level() for pa in self.parents]) + 1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def set_condprob(self):\n",
    "        if len(self.parents):\n",
    "            self.local_conditional_probs = self.local_marginal_probs.copy()\n",
    "            pa_comb = 1\n",
    "            for pa in self.parents:\n",
    "                pa_comb *= pa.num_vals\n",
    "                self.local_conditional_probs = self.local_conditional_probs.merge(pa.local_marginal_probs, how=\"cross\")\n",
    "            \n",
    "            # Generating conditional probability, constraints: sum (P(X=x|Z=z)) = 1 for all x\n",
    "            self.local_conditional_probs['prob'] = [1] * len(self.local_conditional_probs)\n",
    "            self.local_conditional_probs = self.local_conditional_probs.sort_values(by=[f'X{pa.id}' for pa in self.parents])\n",
    "            for i in range(pa_comb):\n",
    "                self.local_conditional_probs['prob'].iloc[self.num_vals*i:self.num_vals*(i+1)] = np.random.dirichlet([self.alpha] * self.num_vals).flatten()\n",
    "        return\n",
    "    \n",
    "    def set_margprob(self, dirichlet_alpha=1):\n",
    "        if not len(self.parents):\n",
    "            probs = np.random.dirichlet([dirichlet_alpha] * self.num_vals).flatten()\n",
    "            try:\n",
    "                old_probs = self.local_marginal_probs['prob']\n",
    "                while np.sqrt((old_probs - probs).pow(2).sum()) < 0.25:\n",
    "                    probs = np.random.dirichlet([dirichlet_alpha] * self.num_vals).flatten()\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "            self.local_marginal_probs['prob'] = probs.flatten()\n",
    "        return\n",
    "    \n",
    "    def sample(self):\n",
    "        if len(self.parents):\n",
    "            conditions = np.array([True for _ in range(len(self.local_conditional_probs))]) # type:ignore\n",
    "            for pa in self.parents:\n",
    "                select = (self.local_conditional_probs[f'X{pa.id}'] == pa.cur_val).to_numpy()   # type:ignore\n",
    "                conditions = np.logical_and(conditions,select)\n",
    "            cond_df = self.local_conditional_probs[conditions]  # type:ignore\n",
    "            self.cur_val = np.random.choice(cond_df[f'X{self.id}'], size=1, p=cond_df[f'prob']).item()\n",
    "        else:\n",
    "            self.cur_val = np.random.choice(self.local_marginal_probs[f'X{self.id}'], size=1, p=self.local_marginal_probs[f'prob']).item()\n",
    "        return\n",
    "        \n",
    "\n",
    "class DAG:\n",
    "    def __init__(self, adj_mtx, max_numvals, alpha) -> None:\n",
    "        self.adj_mtx = adj_mtx\n",
    "        self.nodes = [Node(np.random.randint(2, max_numvals), i + 1, alpha) for i in range(adj_mtx.shape[0])]\n",
    "        self.__endogeneous_nodes = []\n",
    "        self.__render_adjmtx()\n",
    "        self.__order_nodes()\n",
    "        self.__init_condprobs()\n",
    "        self.__init_margprob()\n",
    "        \n",
    "    def __render_adjmtx(self):\n",
    "        for i in range(self.adj_mtx.shape[0]):\n",
    "            parents = [self.nodes[j] for j in range(self.adj_mtx.shape[0]) if self.adj_mtx[j][i] == 1]\n",
    "            self.nodes[i].set_parents(parents)  # type:ignore\n",
    "            if len(parents) == 0:\n",
    "                self.__endogeneous_nodes.append(self.nodes[i])\n",
    "        return\n",
    "    \n",
    "    def __order_nodes(self):\n",
    "        self.nodes.sort(key=lambda item: item.get_level())\n",
    "        return\n",
    "    \n",
    "    def __init_condprobs(self):\n",
    "        for node in self.nodes:\n",
    "            node.set_condprob()    # type:ignore\n",
    "        return\n",
    "    \n",
    "    def __init_margprob(self):\n",
    "        for node in self.nodes:\n",
    "            node.set_margprob(1.0)    # type:ignore\n",
    "        return\n",
    "    \n",
    "    def reinit_endoprob(self, dirichlet_alpha):\n",
    "        chosen_id = np.random.choice([i for i in range(len(self.__endogeneous_nodes))], size=1).item()\n",
    "        self.__endogeneous_nodes[chosen_id].set_margprob(dirichlet_alpha)\n",
    "        return\n",
    "    \n",
    "    def disseminate(self, n):\n",
    "        df = pd.DataFrame(columns=[f'X{node.id}' for node in self.nodes])\n",
    "        for i in tqdm(range(n), leave=False):\n",
    "            res = []\n",
    "            for node in self.nodes:\n",
    "                # print(f\"X{node.id}-->\", end=\"\")\n",
    "                node.sample()\n",
    "                res.append(node.cur_val)\n",
    "            # print(\"|\")\n",
    "            df.loc[len(df),:] = res  # type:ignore\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from utils import is_acyclic\n",
    "\n",
    "def gen_data(dag, n=10000, savepath=\"./data\", filename=\"output.csv\"):\n",
    "    df = dag.disseminate(n)\n",
    "    \n",
    "    if filename is not None:\n",
    "        res_path = os.path.join(savepath)\n",
    "        if not Path(res_path).exists():\n",
    "            os.makedirs(res_path)\n",
    "        \n",
    "        df.to_csv(os.path.join(res_path, filename), index=False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import compute_mll\n",
    "from typing import List\n",
    "\n",
    "def compute_mll(summary_with_ch: pd.DataFrame, potential_parent: list, num_env):\n",
    "    if len(potential_parent):\n",
    "        marginalized_ch = summary_with_ch.groupby(potential_parent)['count'].sum().reset_index()\n",
    "        output = summary_with_ch.merge(marginalized_ch, on=potential_parent, how='left')            \n",
    "        output.insert(0, f'probs_{num_env}', output['count_x']/output['count_y'])\n",
    "        output.insert(0, f'joint_{num_env}', output['count_x']/output['count_x'].sum())\n",
    "        mll = np.array(output['count_x']).dot(np.log(output[f'probs_{num_env}'])).item()\n",
    "        output = output.drop(['count_x', 'count_y'], axis=1)\n",
    "        # return mll, output.rename({'count_y': f'count_y{num_env}', 'count_x': f'count_x{num_env}'}, axis=1)\n",
    "        return mll, output\n",
    "    else:\n",
    "        output = summary_with_ch.copy()\n",
    "        output.insert(0, f'probs_{num_env}', output['count']/output['count'].sum())\n",
    "        mll = np.array(output['count']).dot(np.log(output[f'probs_{num_env}'])).item()\n",
    "        output = output.drop(['count'], axis=1)\n",
    "        return mll, output\n",
    "\n",
    "\n",
    "def compute_variance_viasilos(silos: List[pd.DataFrame], variable: str, parents: list, verbose=False):\n",
    "    conditional_probs_record = silos[0][parents + [variable]].groupby(parents + [variable]).count().reset_index()\n",
    "    mll_list = []\n",
    "    env = 0\n",
    "    for data in silos:\n",
    "        vertical_sampled_data = data[parents + [variable]]\n",
    "        vertical_sampled_data.insert(0, 'count', [1] * len(vertical_sampled_data))\n",
    "        \n",
    "        summary_with_ch = vertical_sampled_data.groupby(parents + [variable])['count'].sum().reset_index()\n",
    "        mll, output = compute_mll(summary_with_ch, parents, env)\n",
    "        conditional_probs_record = conditional_probs_record.merge(output, on=parents + [variable], how='left')\n",
    "        mll_list.append(mll)\n",
    "        env += 1\n",
    "            \n",
    "    mean_mll = np.mean(mll_list)\n",
    "    var_avg = conditional_probs_record.iloc[:, len(parents) + 1:].var(axis=1, skipna=True).mean()\n",
    "    if verbose:\n",
    "        print(conditional_probs_record)\n",
    "    return var_avg, mean_mll, conditional_probs_record\n",
    "\n",
    "\n",
    "def compute_weighted_variance_viasilos(silos: List[pd.DataFrame], variable: str, parents: list, verbose=False):\n",
    "    variance, _, df = compute_variance_viasilos(silos, variable, parents, verbose=verbose)\n",
    "    if len(parents):\n",
    "        joint_mat = np.array([df[f'joint_{i}'] for i in range(len(silos))]).T\n",
    "        probs_mat = np.array([df[f'probs_{i}'] for i in range(len(silos))]).T\n",
    "        probs_mean = np.array([np.mean(probs_mat[i][~np.isnan(probs_mat[i])], keepdims=True) for i in range(probs_mat.shape[0])])\n",
    "        prod = joint_mat * (probs_mat - probs_mean)**2\n",
    "        return np.mean(prod[~np.isnan(prod)])\n",
    "    else:\n",
    "        return variance\n",
    "\n",
    "\n",
    "def get_condprob(dag, node_id):\n",
    "    if len(dag.nodes[node_id].parents):\n",
    "        return dag.nodes[node_id].local_conditional_probs\n",
    "    else:\n",
    "        return dag.nodes[node_id].local_marginal_probs\n",
    "    \n",
    "\n",
    "def compute_condprob(df: pd.DataFrame, variable: str, conditioned_vars: list):\n",
    "    vertical_sampled_data = df[conditioned_vars + [variable]]\n",
    "    vertical_sampled_data.insert(0, 'count', [1] * len(vertical_sampled_data))\n",
    "    summary_with_ch = vertical_sampled_data.groupby([variable] + conditioned_vars)['count'].sum().reset_index()\n",
    "    _, output = compute_mll(summary_with_ch, conditioned_vars, 0)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bnlearn as bn\n",
    "\n",
    "model = bn.import_DAG('../data/munin.bif', verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataname = \"munin\"\n",
    "adj_mtx = model['adjmat'].to_numpy() * 1\n",
    "# data = json.load(open(f\"../CausalBKAI/data/TestData/bnlearn_discrete_10000/truth_dag_adj/{dataname}.json\", \"r\"))\n",
    "# adj_mtx = np.array(data['Adj'])\n",
    "\n",
    "\n",
    "# adj_mtx = np.array(\n",
    "#     [[0,1,0],\n",
    "#      [0,0,1],\n",
    "#      [0,0,0]]\n",
    "# )\n",
    "\n",
    "mi = 3\n",
    "di = 5\n",
    "\n",
    "dag = DAG(adj_mtx, max_numvals=mi, alpha=di)\n",
    "# get_condprob(dag, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# track_endo = get_condprob(dag, 0)[['X1']].groupby(['X1']).sum().reset_index()\n",
    "n = 10\n",
    "silos = []\n",
    "for i in range(n):\n",
    "    dag.reinit_endoprob(dirichlet_alpha=di)\n",
    "    # track_endo = track_endo.merge(get_condprob(dag, 0).rename({\"prob\": f\"prob{i}\"}, axis=1), how='left', on=['X1'])\n",
    "    df = gen_data(dag, 5000, savepath=f\"../data/distributed/{dataname}/m{mi}_d{di}_n{n}\", filename=f\"silo-{i}.csv\") # f\"silo-{i}.csv\"\n",
    "    silos.append(df)\n",
    "\n",
    "# track_endo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(f\"../data/distributed/{dataname}/adj.txt\", adj_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_condprob(dag, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_condprob(dag, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_condprob(dag, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance = compute_weighted_variance_viasilos(silos, 'X2', ['X1'], verbose=True)\n",
    "variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance = compute_weighted_variance_viasilos(silos, 'X1', ['X2'], verbose=True)\n",
    "variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance= compute_weighted_variance_viasilos(silos, 'X3', ['X1', 'X2'], verbose=False)\n",
    "variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_node = 20\n",
    "p = 1/(num_node - 1)\n",
    "\n",
    "graph = nx.erdos_renyi_graph(n=num_node, p=p, seed=0, directed=True)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        cycle_list = nx.find_cycle(graph, orientation='original')\n",
    "        if len(cycle_list):\n",
    "            random.shuffle(cycle_list)\n",
    "            a, b, type = cycle_list[0]\n",
    "            graph.remove_edge(a, b)\n",
    "        else:\n",
    "            break\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_mtx = np.zeros([num_node, num_node])\n",
    "for edge in graph.edges:\n",
    "    a, b = edge\n",
    "    adj_mtx[a][b] = 1\n",
    "    \n",
    "outdegrees = np.sum(adj_mtx, axis=0, keepdims=True)\n",
    "indegrees = np.sum(adj_mtx, axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "if outdegrees.max() < indegrees.max():\n",
    "    adj_mtx = adj_mtx.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = 3\n",
    "di = 1\n",
    "dag = DAG(adj_mtx, max_numvals=mi, alpha=di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "# silos = []\n",
    "for i in range(n):\n",
    "    dag.reinit_endoprob(dirichlet_alpha=1)\n",
    "    df = gen_data(dag, 5000, savepath=f\"./data/distributed/erdos_renyi/d{num_node}_p{p}/m{mi}_d{di}_n{n}\", filename=f\"silo-{i}.csv\") # f\"silo-{i}.csv\"\n",
    "    # silos.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./data/distributed/erdos_renyi/d{num_node}_p{p}/adj.txt\", \"w\") as f:\n",
    "    np.savetxt(f, adj_mtx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "\n",
    "def simulate_dag(d, s0):\n",
    "    def _random_permutation(M):\n",
    "        # np.random.permutation permutes first axis only\n",
    "        P = np.random.permutation(np.eye(M.shape[0]))\n",
    "        return P.T @ M @ P\n",
    "\n",
    "    def _random_acyclic_orientation(B_und):\n",
    "        return np.tril(_random_permutation(B_und), k=-1)\n",
    "\n",
    "    def _graph_to_adjmat(G):\n",
    "        return np.array(G.get_adjacency().data)\n",
    "\n",
    "    # Erdos-Renyi\n",
    "    G_und = ig.Graph.Erdos_Renyi(n=d, m=s0)\n",
    "    B_und = _graph_to_adjmat(G_und)\n",
    "    B = _random_acyclic_orientation(B_und)\n",
    "    \n",
    "    B_perm = _random_permutation(B)\n",
    "    return B_perm\n",
    "\n",
    "\n",
    "def simulate_parameter(B, w_ranges=((-2.0, -0.5), (0.5, 2.0))):\n",
    "    W = np.zeros(B.shape)\n",
    "    S = np.random.randint(len(w_ranges), size=B.shape)  # which range\n",
    "    for i, (low, high) in enumerate(w_ranges):\n",
    "        U = np.random.uniform(low=low, high=high, size=B.shape)\n",
    "        W += B * (S == i) * U\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, weights, id) -> None:\n",
    "        \"\"\"\n",
    "            id: Int\n",
    "            alpha: Float (dirichlet's alpha)\n",
    "        \"\"\"\n",
    "        self.id = id\n",
    "        self.generative_weights = weights\n",
    "        self.parents = []\n",
    "        self.cur_val = -1\n",
    "        self.mean = np.random.randn()\n",
    "    \n",
    "    def set_parents(self, parents):\n",
    "        self.parents = parents\n",
    "        return\n",
    "        \n",
    "    def get_level(self):\n",
    "        if len(self.parents):\n",
    "            return max([pa.get_level() for pa in self.parents]) + 1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def sample(self):\n",
    "        if len(self.parents):\n",
    "            current_vals = np.zeros_like(self.generative_weights)\n",
    "            for pa in self.parents:\n",
    "                id = pa.id - 1\n",
    "                current_vals[id] = pa.cur_val\n",
    "                \n",
    "            self.cur_val = (current_vals @ self.generative_weights).item()\n",
    "        else:\n",
    "            self.cur_val = np.random.normal(self.mean, scale=1, size=1).item()\n",
    "        return\n",
    "\n",
    "\n",
    "class DAG:\n",
    "    def __init__(self, adj_mtx:np.ndarray) -> None:\n",
    "        self.adj_mtx = adj_mtx\n",
    "        self.nodes = [Node(adj_mtx[:,i].flatten(), i + 1) for i in range(adj_mtx.shape[0])]\n",
    "        self.__endogeneous_nodes = []\n",
    "        self.__render_adjmtx()\n",
    "        self.__order_nodes()\n",
    "        \n",
    "    def __render_adjmtx(self):\n",
    "        for i in range(self.adj_mtx.shape[0]):\n",
    "            parents = [self.nodes[j] for j in range(self.adj_mtx.shape[0]) if self.adj_mtx[j][i] != 0]\n",
    "            self.nodes[i].set_parents(parents)  # type:ignore\n",
    "            if len(parents) == 0:\n",
    "                self.__endogeneous_nodes.append(self.nodes[i])\n",
    "        return\n",
    "    \n",
    "    def __order_nodes(self):\n",
    "        self.nodes.sort(key=lambda item: item.get_level())\n",
    "        return\n",
    "    \n",
    "    def disseminate(self, n):\n",
    "        df = pd.DataFrame(columns=[f'X{node.id}' for node in self.nodes])\n",
    "        for i in tqdm(range(n), leave=False):\n",
    "            res = []\n",
    "            for node in self.nodes:\n",
    "                node.sample()\n",
    "                res.append(node.cur_val)\n",
    "            df.loc[len(df),:] = res  # type:ignore\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "d, s = 10, 15\n",
    "adj_mtx = simulate_dag(d, s)\n",
    "w_mtx = simulate_parameter(adj_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dag = DAG(w_mtx)\n",
    "df = dag.disseminate(10000)\n",
    "df = df.reindex(sorted(df.columns, key=lambda item: int(item[1:])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(f\"../data/notears/linearGaussian/W_true_{d}_{s}.csv\", adj_mtx, delimiter=\",\")\n",
    "np.savetxt(f\"../data/notears/linearGaussian/raw/X_{d}_{s}.csv\", df.to_numpy(), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "easyFL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
